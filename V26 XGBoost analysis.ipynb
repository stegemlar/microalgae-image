{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f9526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import shap \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pretreat data - data is loaded as csv files from individual class measurements \n",
    "\n",
    "os.chdir() #Give file location here\n",
    "\n",
    "df_gf = pd.read_csv('Measurements_Greenflag.csv') \n",
    "df_gr = pd.read_csv('Measurements_Greenround.csv')\n",
    "df_rf = pd.read_csv('Measurements_Redflag.csv')\n",
    "df_rr = pd.read_csv('Measurements_Redround.csv')\n",
    "df_ot = pd.read_csv('Measurements_Others.csv')\n",
    "\n",
    "# Add labels to each dataframe \n",
    "\n",
    "df_gf['Label']= 'Greenflag'\n",
    "df_gr['Label']= 'Greenround'\n",
    "df_rf['Label']= 'Redflag'\n",
    "df_rr['Label']= 'Redround'\n",
    "df_ot['Label']= 'Others'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e8bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to one data set and order them randomly to prevent order bias\n",
    "\n",
    "df = pd.concat([df_gf,df_gr,df_rf,df_rr,df_ot])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c08425-989e-45c3-9648-cb10e6954c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_df = df.sample(frac=1).reset_index(drop = True) #Shuffle rows to prevent bias\n",
    "\n",
    "#Format data to have one dataset of what we want to predict and one of what should be used to predict \n",
    "X = rand_df.drop('Label', axis =1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599315d1-b63e-4b0f-85ad-0207c4a2ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rand_df['Label'].copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(label_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a10b4a-67ec-4fa4-a10c-1cb3c086d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, stratify = y) # Splits dataset in training and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a841f0-bdb6-45c3-aeac-019c7dcf52cf",
   "metadata": {},
   "source": [
    "## Run XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18517073-625f-43cb-bb8f-be655f1ad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'multi:softmax',\n",
    "                            early_stopping_rounds = 20, \n",
    "                            eval_metric ='mlogloss') \n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose = True,\n",
    "            eval_set=[(X_test, y_test)])\n",
    "clf_xgb.save_model('V26_Classifiermodel.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4af0d2-27e3-48ed-84eb-be144ab58330",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Parameter optimization \n",
    "\n",
    " #Round 1\n",
    " param_grid = {\n",
    "     'max_depth': [3,4,5],\n",
    "     'learning_rate':[0.1,0.5,1],\n",
    "     'gamma': [0,0.05,0.1],\n",
    "     'reg_lambda':[0,1.0,10.0],\n",
    " }\n",
    " ##Output: Best Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 4, 'reg_lambda': 0, 'scale_pos_weight': 1}\n",
    "\n",
    " #Round 2\n",
    " param_grid = {\n",
    "    'max_depth': [4],\n",
    "    'learning_rate':[0.13,0.14,0.15],\n",
    "    'gamma': [0.12],\n",
    "    'reg_lambda':[0.01],\n",
    " }\n",
    " ##Output: Best Parameters: {'gamma': 0.12, 'learning_rate': 0.13, 'max_depth': 4, 'reg_lambda': 0.01}\n",
    "\n",
    "\n",
    " optimal_params=GridSearchCV(estimator=xgb.XGBClassifier(objective='multi:softmax',\n",
    "                                                         num_class=5,\n",
    "                                                         ),\n",
    "                                                         param_grid = param_grid,\n",
    "                                                         scoring='roc_auc_ovr', \n",
    "                                                         verbose=0, \n",
    "                                                         n_jobs=10,\n",
    "                                                         cv=3\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d22fc9-27d0-4bf1-baef-cacf459e50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Optimize parameters \n",
    " optimal_params.fit(X_train,\n",
    "                    y_train,\n",
    "                    eval_set=[(X_test, y_test)],\n",
    "                    verbose = False)\n",
    " print(\"Best Parameters:\", optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5263f-691a-42c2-92d7-8644baa6f039",
   "metadata": {},
   "source": [
    "## Build XGBoost model again with optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b405dc-063b-47a5-9dca-91005454009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'multi:softmax',\n",
    "                          gamma=0.12,\n",
    "                          learning_rate=0.13,\n",
    "                          max_depth=4,\n",
    "                            reg_lambda=0.01,\n",
    "                            early_stopping_rounds = 30, \n",
    "                            eval_metric =['mlogloss','merror'],\n",
    "                            \n",
    "                            num_class =5\n",
    "                           ) \n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose = True,\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399b412-4414-4d6a-953f-7903b6e8ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Overview of Hyperparameters\n",
    "params = clf_xgb.get_params()\n",
    "print(\"Learning rate:\", params.get('learning_rate'))\n",
    "print(\"Max depth:\", params.get('max_depth'))\n",
    "print(\"Gamma:\", params.get('gamma'))  # Added line for gamma\n",
    "print(\"Reg lambda:\", params.get('reg_lambda'))\n",
    "\n",
    "\n",
    "if hasattr(clf_xgb, 'best_iteration'):\n",
    "    num_trees = clf_xgb.best_iteration + 1\n",
    "    print(f\"The model contains {num_trees} trees.\")\n",
    "\n",
    "\n",
    "\n",
    "if hasattr(clf_xgb, 'evals_result'):\n",
    "    evals_result = clf_xgb.evals_result()\n",
    "    if 'merror' in evals_result['validation_0']:\n",
    "        last_error_rate = evals_result['validation_0']['merror'][-1]\n",
    "        training_accuracy = 1 - last_error_rate\n",
    "        print(f\"Training accuracy: {training_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f0aa8-3e2c-4803-97bf-e4f56238c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize validation (Confusion matrix)\n",
    "predictions = clf_xgb.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Greenflag', 'Greenround', 'Others', 'Redflag', 'Redround'])\n",
    "fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "disp.plot(values_format='.1f', cmap='viridis', ax=ax)\n",
    "\n",
    "ax.set_yticklabels(['Greenflag', 'Greenround', 'Others', 'Redflag', 'Redround'], rotation=90, verticalalignment='center')\n",
    "\n",
    "ax.set_xlabel('Predicted Label', labelpad=10)\n",
    "\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('Tmodel_confusion_matrix.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c760e-3076-4a2d-88c0-a687c74702f3",
   "metadata": {},
   "source": [
    "## Make a Tree (for illustration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706cb7a-cafb-422e-93f5-3a9246543f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'multi:softmax',\n",
    "                           gamma=0,\n",
    "                           learning_rate=0.1,\n",
    "                           max_depth=4,\n",
    "                           reg_lambda=10,\n",
    "                           n_estimators=1) \n",
    "clf_xgb.fit(X_train,\n",
    "            y_train)\n",
    "\n",
    "bst = clf_xgb.get_booster()\n",
    "for importance_type in ('weight','gain','cover','total_gain','total_cover'): \n",
    "    print('%s: ' % importance_type, bst.get_score(importance_type=importance_type))\n",
    "\n",
    "node_params={'shape':'box',\n",
    "             'style':'filled, rounded',\n",
    "             'fillcolor':'#78cbe'}\n",
    "leaf_params={'shape':'box', \n",
    "             'style':'filled', \n",
    "             'fillcolor':'#ab2c2c'}\n",
    "\n",
    "graph_data = xgb.to_graphviz(clf_xgb, num_trees=0, size=\"10,10\",\n",
    "                condition_node_params=node_params,\n",
    "                leaf_node_params=leaf_params)\n",
    "\n",
    "graph_data.view(filename='xgboost_tree_500_imageanalysis') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd844641-d490-482c-b446-bde6b3825e00",
   "metadata": {},
   "source": [
    "## Check influence of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f49f9-5897-4cca-9091-0dc262031e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(clf_xgb, max_num_features=34, importance_type='weight')\n",
    "plt.show()\n",
    "\n",
    "# Save the plot to a file\n",
    "ax.figure.savefig('importance.png',bbox_inches='tight')  \n",
    "\n",
    "\n",
    "\n",
    "importance = clf_xgb.get_booster().get_score(importance_type='gain')\n",
    "sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "for feature, importance in sorted_importance: \n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d835306-4a5a-48ad-81fc-ba3ea102b5e1",
   "metadata": {},
   "source": [
    "## SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957ff9bb-39ee-4dc9-9464-f4092aa0459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X_test is a DataFrame with the correct number of feature columns\n",
    "#feature_names = ['Area','Mean','StdDev','Mode','Min','Max','X','Y','XM','YM','Perim.','BX','BY','Width','Height','Major','Minor','Angle','Circ.','Feret','IntDen','Median','Skew','Kurt','%Area','RawIntDen','FeretX','FeretY','FeretAngle','MinFeret','AR','Round','Solidity']  # Replace with actual feature names\n",
    "\n",
    "\n",
    "# Explain predictions with SHAP values \n",
    "explainer = shap.TreeExplainer(clf_xgb, feature_perturbation='interventional') \n",
    "shap_values = explainer(X_test, check_additivity=False) \n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "#Array with correct predictions \n",
    "a = ([0,8,1,3,2])\n",
    "\n",
    "#Array with class names\n",
    "names=(['Greenflag','Greenround','Others','Redflag','Redround'])\n",
    "\n",
    "# Get model's prediction for the class\n",
    "for j in range(len(a)):\n",
    "    for i in  range(num_classes): \n",
    "        model_prediction = clf_xgb.predict_proba(X_test)[a[j],i]\n",
    "        plt.figure()\n",
    "        shap.plots.waterfall(shap_values[a[j],:,i], show = False, max_display = 10)\n",
    "        plt.title(f\"Class: {names[i]} - Model Prediction: {model_prediction:.2f}\")\n",
    "        plt.savefig(f\"Waterfall {i,j}.png\",bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
